{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi2rTgDiQtsXIQElSexJZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plnu-biomechanics/kin6015/blob/main/notebooks/kin6015_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.pointloma.edu/sites/default/files/styles/basic_page/public/images/PLNU_Biomechanics_Lab_green_yellowSD_HiRes.png\" width=400>\n",
        "\n",
        "## **KIN 6015 Biomechanical Basis of Human Movement**\n",
        "Instructor: Arnel Aguinaldo, PhD\n",
        "\n",
        "**Lab 1 Data Processing**\n",
        "\n",
        "In this lab, gait analysis data was collected with the marker-based and markerless motion capture systems and spatiotemporal metrics and inverse kinematics (IK) were estimated using Visual3D. The data were then exported as text (*.txt) files and uploaded to the class repository in the lab's [GitHub](https://github.com/plnu-biomechanics).\n",
        "\n",
        "To further process the data for this lab, follow the steps in this **Colab notebook**, which contains instructions and sample code on how to wrangle and analyze the data.\n"
      ],
      "metadata": {
        "id": "BlhMHK7IAzfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create your own Colab Notebook\n",
        "\n",
        "1. Go to **File -> New notebook in Drive** to open a new notebook in your Python environment:<br>\n",
        "<img src=\"https://raw.githubusercontent.com/plnu-biomechanics/kin6015/main/notebooks/images/file_notebook.png\" width=450>\n",
        "\n",
        "2. Rename your Colab notebook using this naming format: **lastname_group_lab#.ipynb** (e.g., \"aguinaldo_targaryen_lab1.ipynb\")\n",
        "3. Click on the **+ Code** option above to insert a new code cell: <br>\n",
        "<img src=\"https://raw.githubusercontent.com/plnu-biomechanics/kin6015/main/notebooks/images/addcode.png\" width=280>\n",
        "\n",
        "4. The data you will parse and analyze for this lab will be copied from the lab's GitHub and temporarily stored in your Colab working directory, which can be accessed by clicking on the folder icon in the left menu:<br>\n",
        "<img src=\"https://raw.githubusercontent.com/plnu-biomechanics/kin6015/main/notebooks/images/colab_folder.png\" width=400>\n",
        "\n",
        "5. Copy the following lines of code to import the packages needed for this analysis and to load the data files into your working directory. Be sure to update the `GROUP` variable with your group's name. **Note**: These files are \"runtime\" access only, meaning they are only temporarily stored in your working directory and show up when your notebook is in session. However, the following code cell allows you to clone the zipped files to the working directory each time it is executed.\n"
      ],
      "metadata": {
        "id": "j1Gi2rPXJDOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A3-y3-4GKN-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959ccd43-012e-4d87-8a1e-2fa8a3617ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files in lab directory:\n",
            "['Targaryen_MB_05.txt', 'Targaryen_ML_03.txt', 'Targaryen_ML_01.txt', 'Targaryen_ML_05.txt', 'Targaryen_MB_03.txt', 'spring2026_lab1_targaryen.zip', 'Targaryen_MB_01.txt', 'Targaryen_ML_04.txt', 'Targaryen_MB_04.txt', 'Targaryen_MB_02.txt', 'Targaryen_ML_02.txt']\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STUDENT INPUT (edit only this line; case-sensitive)\n",
        "# --------------------------------------------------\n",
        "GROUP = \"targaryen\"   # e.g., \"targaryen\", \"stark\", \"lannister\", \"martel\"\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Configuration (do NOT edit below)\n",
        "# These lines create a directory for this lab in your\n",
        "# Colab working directory.\n",
        "# --------------------------------------------------\n",
        "zip_dir = \"kin6015/lab1\"\n",
        "os.makedirs(zip_dir, exist_ok=True)\n",
        "\n",
        "zip_filename = f\"spring2026_lab1_{GROUP}.zip\"\n",
        "\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/\"\n",
        "    \"plnu-biomechanics/kin6015/main/\"\n",
        "    f\"labs/{zip_filename}\"\n",
        ")\n",
        "\n",
        "zip_path = os.path.join(zip_dir, zip_filename)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Download zip file\n",
        "# --------------------------------------------------\n",
        "urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Extract contents from the zipped file\n",
        "# --------------------------------------------------\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(zip_dir)\n",
        "\n",
        "print(\"Extracted files in lab directory:\")\n",
        "print(os.listdir(zip_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588d2968"
      },
      "source": [
        "# Gemini Task\n",
        "#### Prompt:\n",
        "Create a single pandas DataFrame named `combined_df` by iterating through all `.txt` files in the `kin6015/lab1` directory, applying the `parse_txt_file` function to each, and then concatenating the results. Finally, display the head of `combined_df` to verify its structure and content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38bb2b70"
      },
      "source": [
        "## Parse All Files and Combine Data\n",
        "\n",
        "### Subtask:\n",
        "Iterate through all '.txt' files located in the 'kin6015/lab1' directory. Apply the updated `parse_txt_file` function to each file. Collect all the resulting DataFrames into a list, and then concatenate them into a single master DataFrame named `combined_df`. This step will re-attempt to process all files with the corrected parsing logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3e504a",
        "outputId": "d83b9352-7d66-4ad2-b749-d162ea78d8da"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def parse_txt_file(filepath):\n",
        "  \"\"\"Reads a text file, extracts variable names and time-series data, identifies the condition,\n",
        "  and returns a pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    filepath (str): The full path to the text file.\n",
        "\n",
        "  Returns:\n",
        "    pd.DataFrame: A DataFrame containing the extracted data, condition, and filename.\n",
        "  \"\"\"\n",
        "  with open(filepath, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "  # Check if file has enough lines for the expected structure\n",
        "  if len(lines) < 6: # Need at least 6 lines (5 header, 1 data)\n",
        "      raise ValueError(f\"File {os.path.basename(filepath)} has too few lines to parse correctly.\")\n",
        "\n",
        "  # Extract variable names from the 2nd line (index 1), using tab as delimiter\n",
        "  variable_names = lines[1].strip().split('\\t')\n",
        "\n",
        "  # Read time-series data starting from the 6th line (index 5), using tab as delimiter\n",
        "  data_lines = [line.strip().split('\\t') for line in lines[5:] if line.strip()]\n",
        "\n",
        "  # Ensure data_lines is not empty before checking lengths\n",
        "  if not data_lines:\n",
        "      raise ValueError(f\"No data found in file {os.path.basename(filepath)} after header.\")\n",
        "\n",
        "  # Dynamically add 'Frame' if data rows have one more column than variable names\n",
        "  if len(data_lines[0]) == len(variable_names) + 1:\n",
        "      variable_names.insert(0, 'Frame')\n",
        "\n",
        "  # Ensure variable names and data lines match in length AFTER potential adjustment\n",
        "  if len(variable_names) != len(data_lines[0]):\n",
        "      raise ValueError(f\"Column name count ({len(variable_names)}) does not match data column count ({len(data_lines[0])}) in file {os.path.basename(filepath)}.\")\n",
        "\n",
        "  # Create DataFrame\n",
        "  df = pd.DataFrame(data_lines, columns=variable_names)\n",
        "\n",
        "  # Convert numeric columns to appropriate data types\n",
        "  for col in df.columns:\n",
        "    try:\n",
        "      df[col] = pd.to_numeric(df[col])\n",
        "    except ValueError:\n",
        "      pass # Keep as string if not numeric\n",
        "\n",
        "  # Determine 'condition' from filename\n",
        "  filename = os.path.basename(filepath)\n",
        "  if 'MB' in filename.upper(): # Changed to upper() for accurate matching of 'MB'\n",
        "    condition = 'marker-based'\n",
        "  elif 'ML' in filename.upper(): # Changed to upper() for accurate matching of 'ML'\n",
        "    condition = 'markerless'\n",
        "  else:\n",
        "    condition = 'unknown'\n",
        "\n",
        "  # Add 'condition' column\n",
        "  df['condition'] = condition\n",
        "\n",
        "  # Add 'filename' column\n",
        "  df['filename'] = filename\n",
        "\n",
        "  return df\n",
        "\n",
        "print(\"Updated function 'parse_txt_file' to handle tab-delimited data, correct line indexing, and dynamic 'Frame' column and case-sensitive condition check.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated function 'parse_txt_file' to handle tab-delimited data, correct line indexing, and dynamic 'Frame' column and case-sensitive condition check.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c35d0363"
      },
      "source": [
        "**Reasoning**:\n",
        "The `parse_txt_file` function has been updated to handle the 'Frame' column and tab-delimited data. Now, I need to re-run the code to iterate through all `.txt` files in the `kin6015/lab1` directory, apply the updated `parse_txt_file` function to each, collect the resulting DataFrames, and then concatenate them into a single `combined_df`. Finally, the following code displays the head of `combined_df` to verify the structure and content, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139b0294",
        "outputId": "5ce7fb37-1e67-4891-a101-037b3ef83438"
      },
      "source": [
        "import re\n",
        "\n",
        "all_dataframes = []\n",
        "\n",
        "# Filter for .txt files and exclude the zip file\n",
        "text_files = [f for f in file_list if f.endswith('.txt') and not f.endswith('.zip')]\n",
        "\n",
        "for filename in text_files:\n",
        "    filepath = os.path.join(zip_dir, filename)\n",
        "    try:\n",
        "        df = parse_txt_file(filepath)\n",
        "        all_dataframes.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {filename}: {e}\")\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "if all_dataframes:\n",
        "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "    # Let's clean up the variable names by removing\n",
        "    # '_MEAN' or '_Mean' from column names\n",
        "    combined_df.columns = [re.sub(r'_MEAN', '', col) for col in combined_df.columns]\n",
        "    combined_df.columns = [re.sub(r'_Mean', '', col) for col in combined_df.columns]\n",
        "    print(\"Combined DataFrame created successfully. Displaying head:\")\n",
        "    print(combined_df.head())\n",
        "else:\n",
        "    combined_df = pd.DataFrame()\n",
        "    print(\"No dataframes were parsed successfully to combine.\")\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame created successfully. Displaying head:\n",
            "   Frame  Right Knee Angles  Right Ankle Dorsiflexion    Speed  Stride_Length  \\\n",
            "0      1            3.54527                  -4.28667  1.39355        0.99407   \n",
            "1      2            5.48596                  -4.88219      NaN            NaN   \n",
            "2      3            6.19649                  -6.12455      NaN            NaN   \n",
            "3      4            6.24373                  -7.95542      NaN            NaN   \n",
            "4      5            6.29172                  -9.57410      NaN            NaN   \n",
            "\n",
            "   Right_Stance_Time  Ankle Plantarflexion at IC  Peak Right Knee Flexion  \\\n",
            "0            0.69667                    -5.96584                 67.92663   \n",
            "1                NaN                         NaN                      NaN   \n",
            "2                NaN                         NaN                      NaN   \n",
            "3                NaN                         NaN                      NaN   \n",
            "4                NaN                         NaN                      NaN   \n",
            "\n",
            "      condition             filename  Right Ankle Angles  \n",
            "0  marker-based  Targaryen_MB_05.txt                 NaN  \n",
            "1  marker-based  Targaryen_MB_05.txt                 NaN  \n",
            "2  marker-based  Targaryen_MB_05.txt                 NaN  \n",
            "3  marker-based  Targaryen_MB_05.txt                 NaN  \n",
            "4  marker-based  Targaryen_MB_05.txt                 NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete the Analysis\n",
        "\n",
        "After you've completed this lab's analysis, do the following:\n",
        "\n",
        "1. Copy and paste the above plots and tables to your lab report\n",
        "2. Share your Colab notebook with me\n",
        "3. Copy the link to your notebook and submit it along with your report for this lab on Canvas"
      ],
      "metadata": {
        "id": "W0vQo8A1VFOX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d76654db"
      },
      "source": [
        "## Install SPM1D Library\n",
        "\n",
        "### Subtask:\n",
        "Install the `spm1d` library, which is required for Statistical Parametric Mapping analysis. This is not a standard Colab library, so it needs to be installed first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "228ec023"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing the `spm1d` library, which can be done using `!pip install` in a code cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3262c5",
        "outputId": "e87f5349-2c8c-4897-be01-a821a8d9c395"
      },
      "source": [
        "!pip install spm1d\n",
        "print(\"spm1d library installed.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spm1d\n",
            "  Downloading spm1d-0.4.53-py3-none-any.whl.metadata (878 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from spm1d) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from spm1d) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from spm1d) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->spm1d) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->spm1d) (1.17.0)\n",
            "Downloading spm1d-0.4.53-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spm1d\n",
            "Successfully installed spm1d-0.4.53\n",
            "spm1d library installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73b29cf2",
        "outputId": "9b5a1834-fc0d-4830-a70f-8344fa06b097"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# 1. Extract a unique subject/trial identifier from the 'filename' column\n",
        "def extract_subject_id(filename):\n",
        "    match = re.match(r'^(.*?)_(MB|ML)_(\\d+)\\.txt$', filename)\n",
        "    if match:\n",
        "        return f\"{match.group(1)}_{match.group(3)}\"\n",
        "    return None\n",
        "\n",
        "combined_df['subject_id'] = combined_df['filename'].apply(extract_subject_id)\n",
        "\n",
        "print(\"Added 'subject_id' column to combined_df.\")\n",
        "print(combined_df[['filename', 'subject_id']].head())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'subject_id' column to combined_df.\n",
            "              filename    subject_id\n",
            "0  Targaryen_MB_05.txt  Targaryen_05\n",
            "1  Targaryen_MB_05.txt  Targaryen_05\n",
            "2  Targaryen_MB_05.txt  Targaryen_05\n",
            "3  Targaryen_MB_05.txt  Targaryen_05\n",
            "4  Targaryen_MB_05.txt  Targaryen_05\n"
          ]
        }
      ]
    }
  ]
}